{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis With Python\n",
    "### What is Exploratory Analysis?\n",
    "A preliminary step in data analysis to: \n",
    "\n",
    "1. Summarize main characteristics of the data\n",
    "2. Gain better understanding of the data\n",
    "3. Uncover relationships between the data set\n",
    "4. Extract important variables  \n",
    "\n",
    "Our goal here being to answer the question:  \n",
    "\"**What are the characteristics that have the most impact on the car price**?\"\n",
    "\n",
    "---\n",
    "\n",
    "### Introduction\n",
    "\n",
    "Using a test notebook, we start with an import of a few essential libraries  \n",
    "and assigning the data we want to use to a var.  \n",
    "\n",
    "Then we want to initiate our data frame! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats as sts\n",
    "\n",
    "df_data = Path().cwd().parent.parent/\"Data\"/\"Clean_Data\"/\"clean_auto_df.csv\"\n",
    "auto_df = pd.read_csv(df_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "We've already wrangled the data we're using, it's time to focus on what the  \n",
    "data could be telling us. We'll work on visualizing the data to observe  \n",
    "association.\n",
    "\n",
    "**Functions commonly used in EDA:**  \n",
    "\n",
    "- describe()\n",
    "- info()\n",
    "- value_counts()\n",
    "- linspace()\n",
    "- cut()\n",
    "- boxplot()\n",
    "- scatter()\n",
    "- show()\n",
    "- groupby()\n",
    "- get_group()\n",
    "- f_oneway()\n",
    "- corr()  \n",
    "\n",
    "---  \n",
    "\n",
    "### Descriptive Statistics  \n",
    "\n",
    "Below, we start with descriptive statistics, which tells us a summary of the  \n",
    "basic statistical numerical data, excluding object and bool types unless  \n",
    "passed a paramater to do so. Naan values are also excluded in these statistics.  \n",
    "\n",
    "**Ex.**  \n",
    "`print(auto_df.describe(include='all'))` *A special string keyword in pandas*  \n",
    "\n",
    "`print(auto_df.describe(include=[bool]))` *Only describes columns with bool*  \n",
    "\n",
    "This function will give you a clearer idea of the distribution of your  \n",
    "different variables; later we'll visualize this data with a boxplot.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto_df.head(20)\n",
    "print(auto_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "**What about the descriptive statistics for our categorical data?**  \n",
    "\n",
    "To get quick descriptive information in a user-friendly output, you want to  \n",
    "pair `value_counts()` with `to_frame()`. Value_counts() to get the frequency  \n",
    "of each value in the specified column--for example, `auto_df[\"drive-wheels\"]`,  \n",
    "and then to_frame() for the desired presentation.      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_wheel_counts = auto_df[\"drive-wheels\"].value_counts().to_frame()\n",
    "drive_wheel_counts.columns = ['value_counts']\n",
    "drive_wheel_counts.index.name = 'drive-wheels'\n",
    "\n",
    "print(drive_wheel_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "The next important part of EDA and descriptive analytics is visualization.  \n",
    "\n",
    "We can visualize data with one of the most common EDA tools which allows us to  \n",
    "determine data distribution at a glance.  \n",
    "\n",
    "It is *primarily effective* with **grouped categorical data** (for example,  \n",
    "drive-wheels) and sometimes binned continuous/numerical data. With  \n",
    "**categorical data** we can see how our target variable compares to our  \n",
    "predictor variable. For **numerical data** we can analyze a column with a wide  \n",
    "range to compare your target variable across those ranges (low, med, high).  \n",
    "\n",
    "**What boxplots can tell you**  \n",
    "\n",
    "- **Box (IQR):** The interquartile range (Q1 to Q3) shows where the middle 50%  \n",
    "  of your data lies. A small box means low variability; a large box means  \n",
    "  greater spread among typical values.\n",
    "\n",
    "- **Median line:** This tells you the central value. If it’s not centered in  \n",
    "  the box, the distribution is skewed (e.g., median closer to  \n",
    "  Q1 = positive/right skew).\n",
    "\n",
    "- **Whiskers:** Typically extend to 1.5×IQR or to min/max in your data. If  \n",
    "  whiskers are uneven in length, this hints at skewness or asymmetry.\n",
    "\n",
    "- **Outliers (dots):** Individual points beyond the whiskers flag unusual  \n",
    "  values. A high number of outliers might suggest:\n",
    "\n",
    "  - *Heavy-tailed distribution*\n",
    "\n",
    "  - *Data entry errors*\n",
    "  \n",
    "  - *Real-world phenomena needing explanation*  \n",
    "\n",
    "If there is **significant overlap** in the IQR of different groups, it is NOT  \n",
    "a good predictor of price.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=\"price\", x=\"drive-wheels\", data=auto_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is an example using binning on numerical data\n",
    "bins = np.linspace(min(auto_df[\"horsepower\"]), max(auto_df[\"horsepower\"]), 4)\n",
    "group_names = ['low', 'medium', 'high']\n",
    "\n",
    "hp_binned = pd.cut(\n",
    "    auto_df[\"horsepower\"],\n",
    "    bins,\n",
    "    labels=group_names,\n",
    "    include_lowest=True\n",
    ")\n",
    "hp_df = hp_binned.to_frame(name=\"horsepower-binned\")\n",
    "hp_df[\"price\"] = auto_df[\"price\"]\n",
    "\n",
    "# hp_df.head()\n",
    "\n",
    "\n",
    "sns.boxplot(y=\"price\", x=\"horsepower-binned\", data=hp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(auto_df[\"horsepower\"], bins=10)\n",
    "plt.xlabel(\"Horsepower\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Horsepower Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Another visualization tool we can use is the **scatter plot**. Truly made for  \n",
    "comparing continuous data (target and predictor), it explores the relationship  \n",
    "between the two to identify patterns or trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = auto_df[\"price\"]\n",
    "x = auto_df[\"engine-size\"]\n",
    "plt.scatter(x,y)\n",
    "\n",
    "plt.title(\"Scatterplot of Engine Size vs Price\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.xlabel(\"Engine Size\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Groupby()  \n",
    "\n",
    "While you can apply groupby() to numerical data, it works best when there are  \n",
    "multiple of the same unique values in categorical data. It helps explore  \n",
    "relationships between your target variable and predictors, and if different  \n",
    "categories or category pairs explain variation in the target.  \n",
    "\n",
    "`groupby()` method: \n",
    "\n",
    "- Can be applied on categorical variables  \n",
    "- Group Data into categories  \n",
    "- Single or multiple variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the average price of vehicles and observing how they differ between\n",
    "# categories of \"body-style\" and \"drive-wheels\".\n",
    "\n",
    "df_test = auto_df[['drive-wheels', 'body-style', 'price']]\n",
    "\n",
    "# Grouping by just one category\n",
    "df_group = df_test.groupby(['drive-wheels'], as_index=False)[\"price\"].mean()\n",
    "print(df_group)\n",
    "\n",
    "# as_index=False means the group keys (drive-wheels, body-style) will not \n",
    "# become the index of the result--best for visualization.\n",
    "df_group2 = df_test.groupby(\n",
    "    ['drive-wheels',\n",
    "    'body-style'],\n",
    "    as_index=False\n",
    ").mean()\n",
    "\n",
    "print(df_group2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best for multi-level indexing and easy slicing\n",
    "index_test = auto_df[['drive-wheels', 'body-style', 'price']]\n",
    "index_group = index_test.groupby(['drive-wheels', 'body-style']).mean()\n",
    "\n",
    "avg_rwd_convertible = index_group.loc[(\"rwd\", \"convertible\")]\n",
    "print(avg_rwd_convertible)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "---  \n",
    "\n",
    "### Pivot() Method  \n",
    "\n",
    "While the output of our groupby methods is suitable for some cases, you may  \n",
    "find yourself wanting something easier to read when moving from a data frame  \n",
    "(long) structure to a wider layout.  \n",
    "\n",
    "Enter the `pivot()` method.\n",
    "\n",
    "Here, one vsriable is displayed along the columns and the other variable is  \n",
    "displayed along the rows (as opposed to fatures being columns).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = df_group2.pivot(index=\"drive-wheels\", columns=\"body-style\")\n",
    "df_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Once we have the pivot table, a great way to view the target variable across  \n",
    "multiple variables for visual clues about relationship is with a **heatmap**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_pivot, cmap='RdBu')\n",
    "plt.ylabel(\"drive-wheels\")\n",
    "plt.xlabel(\"body-style\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "---  \n",
    "\n",
    "### Analysis of Variance (ANOVA)\n",
    "\n",
    "ANOVA is a statistical method used to compare the means of two or more groups  \n",
    "to determine if there is a significant difference between them. It answers  \n",
    "questions like:  \n",
    "\n",
    "- Do different car brands have significantly different average prices?\n",
    "- Does a new drug have a different effect than existing treatments?  \n",
    "\n",
    "ANOVA returns two values:  \n",
    "1. **F-static score (F-score):** Measures how much variation exists *between*  \n",
    "group means compared to the variation within each group  \n",
    "(F=variation between group means/variation within groups)\n",
    "   - High f-score means the group means are significantly different\n",
    "   - Low f-score means the group means are very similar  \n",
    "\n",
    "1. **P-value:** Determines if the difference is statistically significant  \n",
    "   - A p-value < 0.05 suggests a strong difference (reject null hypothesis)\n",
    "   - A p-value > 0.05 suggests there is no strong difference (failt to reject  \n",
    "    null hypothesis)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anova = auto_df[[\"make\", \"price\"]]\n",
    "anova_grouped = df_anova.groupby(\"make\")\n",
    "\n",
    "anova_results = sts.f_oneway(\n",
    "    anova_grouped.get_group(\"honda\")[\"price\"],\n",
    "    anova_grouped.get_group(\"subaru\")[\"price\"]\n",
    ")\n",
    "\n",
    "# F-score low, p-val > 0.05. No meaningful price difference between \n",
    "# these brands\n",
    "print(anova_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about testing your entire category/independent variable at one time?\n",
    "# For that, we use Boolean indexing\n",
    "\n",
    "# Look in grouped_test, keep rows where drive-wheels is 'x' value (our \n",
    "# modular condition), and give me the corresponding price from the \"price\"\n",
    "# column\n",
    "grouped_test = auto_df[[\"drive-wheels\", \"price\"]]\n",
    "group1 = grouped_test.loc[grouped_test[\"drive-wheels\"] == \"fwd\", \"price\"]\n",
    "group2 = grouped_test.loc[grouped_test[\"drive-wheels\"] == \"rwd\", \"price\"]\n",
    "group3 = grouped_test.loc[grouped_test[\"drive-wheels\"] == \"4wd\", \"price\"]\n",
    "\n",
    "anova_results2 = sts.f_oneway(group1, group2, group3)\n",
    "print(f\"The ANOVA is: {anova_results2}\")\n",
    "\n",
    "# F-score high, p-val extremely small. There is a strong, meaningful difference\n",
    "# between drive-wheels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "---  \n",
    "\n",
    "### Correlation  \n",
    "\n",
    "Correlation is the statistical metric for measuring to what extent different  \n",
    "numerical variables are interdependent. In other words, when we look at  \n",
    "two variables time, if one variable changes, how does this effect change  \n",
    "in the other variable?\n",
    "\n",
    "We view this correlation on a scatter plot with an included regression line:  \n",
    "- Steep inclines indicate a strong predictor, flat indicates poor\n",
    "- Upward slope = positive correlation, downward slope = negative correlation  \n",
    "\n",
    "*Note: Correlation is not causation. DA mostly deals with correlation.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"horsepower\", y=\"price\", data=auto_df)\n",
    "plt.ylim(0,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### Correlation Statistics (`stats.pearsonr()`) \n",
    "\n",
    "**Pearson Correlation** measures the strength of the correlation between two  \n",
    "features. It returns two values:\n",
    "- Correlation coefficient\n",
    "  - **Close to +1**: Large positive relationship  \n",
    "  - **Close to -1**: Large negative relationship  \n",
    "  - **Close to 0**: No relationship  \n",
    "- P-value\n",
    "  - **P-value < 0.001**: Strong certainty in the result  \n",
    "  - **p-value < 0.05**: Moderate certainty in the result  \n",
    "  - **P-value < 0.1**: Weak certainty in the result  \n",
    "  - **P-value > 0.1**: NO certainty in the result  \n",
    "\n",
    "For the sake of our future modeling, we would go through each numerical feature  \n",
    "and determine the correlation with price to identify the strongest influencing  \n",
    "features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_coef, p_value = sts.pearsonr(auto_df[\"horsepower\"], auto_df[\"price\"])\n",
    "print(f\"The Pearson Coef: {pearson_coef}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Correlation Heatmap  \n",
    "\n",
    "An extremely quick way to both process the pearson coefficient for each data  \n",
    "category compared to every other category. In this instance, we can see how  \n",
    "every other category stacks with our target variable (\"price\").  \n",
    "\n",
    "We must first correlate all of the categories in the df with Pandas' built in  \n",
    "method, `corr()`. Once calculated, we can use `seaborn's heatmap()` function to  \n",
    "visualize the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = auto_df.corr(numeric_only=True)\n",
    "\n",
    "h_map = sns.heatmap(corr, cmap='coolwarm')\n",
    "plt.show()\n",
    "\n",
    "# Exploring correlation between specific features\n",
    "print(auto_df[[\"engine-size\", \"price\"]].corr())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
